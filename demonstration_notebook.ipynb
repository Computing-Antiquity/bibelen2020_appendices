{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2be019",
   "metadata": {},
   "outputs": [],
   "source": [
    "###demonstration notebook for the article \"Computing Danish Bible Translations: A Stylometric Analysis of Bibelen 2020 Compared with DO92\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the texts\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "books = []\n",
    "\n",
    "\n",
    "for book in glob(\"../data1_nopunct/books/*/*/*.txt\"):\n",
    "    book_type = book.split(\"/\")[-2].strip()\n",
    "    book_translator = book.split(\"/\")[-3].strip()\n",
    "    book_name = book.split(\"/\")[-1].split(\".\")[0].replace(book_translator, \"\").strip()\n",
    "    with open(book, \"r\") as f:\n",
    "        book_content = f.read().replace(\"\\n\", \" \").strip()\n",
    "    books.append({\n",
    "        \"type\": book_type,\n",
    "        \"name\": book_name,\n",
    "        \"translator\": book_translator,\n",
    "        \"content\": book_content\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f30c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Length and Vocabulary Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total token count for Table 2\n",
    "\n",
    "\n",
    "\n",
    "book_df = pd.DataFrame(books)\n",
    "\n",
    "# Dataframe contains the number of tokens per book\n",
    "book_df = book_df.assign(count_tokens = pd.DataFrame(books).content.apply(lambda x: len(x.split(\" \"))))\n",
    "\n",
    "# Sum the total number of tokens per translator\n",
    "print(\"===== 1992 total number of tokens =====\")\n",
    "print(book_df[book_df.translator == \"1992\"].count_tokens.sum())\n",
    "print(\"===== 2020 total number of tokens =====\")\n",
    "print(book_df[book_df.translator == \"2020\"].count_tokens.sum())\n",
    "\n",
    "# Difference in number of tokens per book\n",
    "# If the value is positive, the 1992 translation has more tokens than the 2020 translation\n",
    "# If the value is negative, the 2020 translation has more tokens than the 1992 translation\n",
    "diff_tokens = pd.DataFrame(book_df[book_df.translator == \"1992\"].sort_values(\"name\").count_tokens.values - book_df[book_df.translator == \"2020\"].sort_values(\"name\").count_tokens.values)\n",
    "diff_tokens = diff_tokens.assign(name = book_df[book_df.translator == \"1992\"].sort_values(\"name\").name.values)\n",
    "diff_tokens.columns = [\"1992 translation - 2020 translation\", \"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Token counts for Table 3 and NT/OT Token counts in Table 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OT1992 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"1992\")][\"token_count\"].sum()\n",
    "NT1992 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"1992\")][\"token_count\"].sum()\n",
    "OT2020 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"2020\")][\"token_count\"].sum()\n",
    "NT2020 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"2020\")][\"token_count\"].sum()\n",
    "\n",
    "print(\"OT1992\")\n",
    "print(\"NT1992\")\n",
    "print(\"OT2020\")\n",
    "print(\"NT2020\")\n",
    "print(OT1992)\n",
    "print(NT1992)\n",
    "print(OT2020)\n",
    "print(NT2020)\n",
    "\n",
    "token_pivot = book_df.pivot(index=\"name\", columns=\"translator\", values=\"token_count\")\n",
    "token_pivot[\"diff_1992_minus_2020\"] = token_pivot[\"1992\"] - token_pivot[\"2020\"]\n",
    "token_pivot[\"diff_percent_1992_vs_2020\"] = 100 * token_pivot[\"diff_1992_minus_2020\"] / token_pivot[\"2020\"]\n",
    "token_pivot_sorted = token_pivot.sort_values(by=\"diff_1992_minus_2020\", ascending=False)\n",
    "print(token_pivot_sorted)\n",
    "token_pivot_sorted.to_csv(\"token_counts_sorted.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vocabulary Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "book_df = pd.DataFrame(books)\n",
    "\n",
    "# Perform the lemmatization using Danish Spacy model\n",
    "# First, you need to install the large model of Danish Spacy, running\n",
    "# python -m spacy download da_core_news_lg\n",
    "# in the terminal\n",
    "\n",
    "nlp = spacy.load(\"da_core_news_lg\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "book_df[\"lemmatized_content\"] = book_df[\"content\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f60fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique number of lemmas per book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0cc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = book_df.assign(count_lemmas = book_df.lemmatized_content.apply(lambda x: len(set(x.split(\" \")))))\n",
    "print(book_df[[\"name\", \"translator\", \"count_lemmas\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcf580",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculation for Table 5\n",
    "# Unique number of lemmas across all the books\n",
    "print(\"===== 1992 total number of lemmas =====\")\n",
    "print(len(set(\" \".join(book_df[book_df.translator == \"1992\"].lemmatized_content).split(\" \"))))\n",
    "\n",
    "print(\"===== 2020 total number of lemmas =====\")\n",
    "print(len(set(\" \".join(book_df[book_df.translator == \"2020\"].lemmatized_content).split(\" \"))))\n",
    "\n",
    "print(\"===\")\n",
    "print(\"Difference in unique lemmas between 1992 and 2020 over all the bible\")\n",
    "print(len(set(\" \".join(book_df[book_df.translator == \"1992\"].lemmatized_content).split(\" \"))) - len(set(\" \".join(book_df[book_df.translator == \"2020\"].lemmatized_content).split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_unique_lemmas(series):\n",
    "    # Collects all lemmas across the books\n",
    "    lemma_set = set()\n",
    "    for text in series:\n",
    "        for lemma in text.split():\n",
    "            lemma_set.add(lemma.lower())\n",
    "    return len(lemma_set)\n",
    "\n",
    "groups = {\n",
    "    \"GT1992\":  book_df.query('type == \"GT\" and translator == \"1992\"')[\"lemmatized_content\"],\n",
    "    \"NT1992\":  book_df.query('type == \"NT\" and translator == \"1992\"')[\"lemmatized_content\"],\n",
    "    \"GT2020\":  book_df.query('type == \"GT\" and translator == \"2020\"')[\"lemmatized_content\"],\n",
    "    \"NT2020\":  book_df.query('type == \"NT\" and translator == \"2020\"')[\"lemmatized_content\"],\n",
    "}\n",
    "\n",
    "for k, s in groups.items():\n",
    "    print(f\"{k}: {all_unique_lemmas(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_unique_lemmas(series):\n",
    "    # Collects all lemmas across the books\n",
    "    lemma_set = set()\n",
    "    for text in series:\n",
    "        for lemma in text.split():\n",
    "            lemma_set.add(lemma.lower())\n",
    "    return len(lemma_set)\n",
    "\n",
    "groups = {\n",
    "    \"GT1992\":  book_df.query('type == \"GT\" and translator == \"1992\"')[\"lemmatized_content\"],\n",
    "    \"NT1992\":  book_df.query('type == \"NT\" and translator == \"1992\"')[\"lemmatized_content\"],\n",
    "    \"GT2020\":  book_df.query('type == \"GT\" and translator == \"2020\"')[\"lemmatized_content\"],\n",
    "    \"NT2020\":  book_df.query('type == \"NT\" and translator == \"2020\"')[\"lemmatized_content\"],\n",
    "}\n",
    "\n",
    "for k, s in groups.items():\n",
    "    print(f\"{k}: {all_unique_lemmas(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculations for Table 6 and Table 7\n",
    "\n",
    "\n",
    "\n",
    "OT1992 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"1992\")][\"count_lemmas\"].sum()\n",
    "NT1992 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"1992\")][\"count_lemmas\"].sum()\n",
    "OT2020 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"2020\")][\"count_lemmas\"].sum()\n",
    "NT2020 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"2020\")][\"count_lemmas\"].sum()\n",
    "\n",
    "print(\"OT1992\")\n",
    "print(\"NT1992\")\n",
    "print(\"OT2020\")\n",
    "print(\"NT2020\")\n",
    "print(OT1992)\n",
    "print(NT1992)\n",
    "print(OT2020)\n",
    "print(NT2020)\n",
    "\n",
    "token_pivot = book_df.pivot(index=\"name\", columns=\"translator\", values=\"count_lemmas\")\n",
    "token_pivot[\"diff_1992_minus_2020\"] = token_pivot[\"1992\"] - token_pivot[\"2020\"]\n",
    "token_pivot[\"diff_percent_1992_vs_2020\"] = 100 * token_pivot[\"diff_1992_minus_2020\"] / token_pivot[\"2020\"]\n",
    "token_pivot_sorted = token_pivot.sort_values(by=\"diff_1992_minus_2020\", ascending=False)\n",
    "# Rund procentkolonnen til 2 decimaler\n",
    "token_pivot[\"diff_percent_1992_vs_2020\"] = token_pivot[\"diff_percent_1992_vs_2020\"].round(2)\n",
    "print(token_pivot_sorted)\n",
    "token_pivot_sorted.to_csv(\"lemma_counts_sorted.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb012a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pivot_sorted_perc = token_pivot.sort_values(by=\"diff_percent_1992_vs_2020\", ascending=False)\n",
    "print(token_pivot_sorted_perc)\n",
    "token_pivot_sorted_perc.to_csv(\"lemma_counts_sorted_perc.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bib2020app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
