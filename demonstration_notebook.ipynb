{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2be019",
   "metadata": {},
   "outputs": [],
   "source": [
    "###demonstration notebook for the article \"Computing Danish Bible Translations: A Stylometric Analysis of Bibelen 2020 Compared with DO92\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034e08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the texts\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "books = []\n",
    "\n",
    "\n",
    "for book in glob(\"./data1_nopunct/books/*/*/*.txt\"):\n",
    "    book_type = book.split(\"/\")[-2].strip()\n",
    "    book_translator = book.split(\"/\")[-3].strip()\n",
    "    book_name = book.split(\"/\")[-1].split(\".\")[0].replace(book_translator, \"\").strip()\n",
    "    with open(book, \"r\") as f:\n",
    "        book_content = f.read().replace(\"\\n\", \" \").strip()\n",
    "    books.append({\n",
    "        \"type\": book_type,\n",
    "        \"name\": book_name,\n",
    "        \"translator\": book_translator,\n",
    "        \"content\": book_content\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f30c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Length and Vocabulary Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a92f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 1992 total number of tokens =====\n",
      "665987\n",
      "===== 2020 total number of tokens =====\n",
      "652060\n"
     ]
    }
   ],
   "source": [
    "## Total token count for Table 2\n",
    "\n",
    "\n",
    "\n",
    "book_df = pd.DataFrame(books)\n",
    "\n",
    "# Dataframe contains the number of tokens per book\n",
    "book_df = book_df.assign(count_tokens = pd.DataFrame(books).content.apply(lambda x: len(x.split(\" \"))))\n",
    "\n",
    "# Sum the total number of tokens per translator\n",
    "print(\"===== 1992 total number of tokens =====\")\n",
    "print(book_df[book_df.translator == \"1992\"].count_tokens.sum())\n",
    "print(\"===== 2020 total number of tokens =====\")\n",
    "print(book_df[book_df.translator == \"2020\"].count_tokens.sum())\n",
    "\n",
    "# Difference in number of tokens per book\n",
    "# If the value is positive, the 1992 translation has more tokens than the 2020 translation\n",
    "# If the value is negative, the 2020 translation has more tokens than the 1992 translation\n",
    "diff_tokens = pd.DataFrame(book_df[book_df.translator == \"1992\"].sort_values(\"name\").count_tokens.values - book_df[book_df.translator == \"2020\"].sort_values(\"name\").count_tokens.values)\n",
    "diff_tokens = diff_tokens.assign(name = book_df[book_df.translator == \"1992\"].sort_values(\"name\").name.values)\n",
    "diff_tokens.columns = [\"1992 translation - 2020 translation\", \"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaec226",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Token counts for Table 3 and NT/OT Token counts in Table 2\n",
    "\n",
    "book_df[\"token_count\"] = book_df[\"content\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OT1992\n",
      "NT1992\n",
      "OT2020\n",
      "NT2020\n",
      "493479\n",
      "169998\n",
      "463743\n",
      "188232\n",
      "translator   1992   2020  diff_1992_minus_2020  diff_percent_1992_vs_2020\n",
      "name                                                                     \n",
      "26_Ezek     30664  24956                  5708                  22.872255\n",
      "03_Lev      19765  15124                  4641                  30.686326\n",
      "04_Num      22849  18252                  4597                  25.186281\n",
      "02_Exod     26617  22641                  3976                  17.561062\n",
      "05_Deut     26694  23245                  3449                  14.837599\n",
      "...           ...    ...                   ...                        ...\n",
      "18_Job      15717  17647                 -1930                 -10.936703\n",
      "45_Rom       8941  10893                 -1952                 -17.919765\n",
      "42_Luke     23962  25941                 -1979                  -7.628850\n",
      "44_Acts     22513  24886                 -2373                  -9.535482\n",
      "23_Isa      29399  32268                 -2869                  -8.891162\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "OT1992 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"1992\")][\"token_count\"].sum()\n",
    "NT1992 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"1992\")][\"token_count\"].sum()\n",
    "OT2020 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"2020\")][\"token_count\"].sum()\n",
    "NT2020 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"2020\")][\"token_count\"].sum()\n",
    "\n",
    "print(\"OT1992\")\n",
    "print(\"NT1992\")\n",
    "print(\"OT2020\")\n",
    "print(\"NT2020\")\n",
    "print(OT1992)\n",
    "print(NT1992)\n",
    "print(OT2020)\n",
    "print(NT2020)\n",
    "\n",
    "token_pivot = book_df.pivot(index=\"name\", columns=\"translator\", values=\"token_count\")\n",
    "token_pivot[\"diff_1992_minus_2020\"] = token_pivot[\"1992\"] - token_pivot[\"2020\"]\n",
    "token_pivot[\"diff_percent_1992_vs_2020\"] = 100 * token_pivot[\"diff_1992_minus_2020\"] / token_pivot[\"2020\"]\n",
    "token_pivot_sorted = token_pivot.sort_values(by=\"diff_1992_minus_2020\", ascending=False)\n",
    "print(token_pivot_sorted)\n",
    "token_pivot_sorted.to_csv(\"token_counts_sorted.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vocabulary Richness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the lemmatization using Danish Spacy model\n",
    "# First, you need to install the large model of Danish Spacy, running\n",
    "# python -m spacy download da_core_news_lg\n",
    "# in the terminal\n",
    "#restart the notebook after installing the model\n",
    "# Run the notebook from the cell below to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a6c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "books = []\n",
    "\n",
    "\n",
    "for book in glob(\"./data1_nopunct/books/*/*/*.txt\"):\n",
    "    book_type = book.split(\"/\")[-2].strip()\n",
    "    book_translator = book.split(\"/\")[-3].strip()\n",
    "    book_name = book.split(\"/\")[-1].split(\".\")[0].replace(book_translator, \"\").strip()\n",
    "    with open(book, \"r\") as f:\n",
    "        book_content = f.read().replace(\"\\n\", \" \").strip()\n",
    "    books.append({\n",
    "        \"type\": book_type,\n",
    "        \"name\": book_name,\n",
    "        \"translator\": book_translator,\n",
    "        \"content\": book_content\n",
    "    })\n",
    "\n",
    "book_df = pd.DataFrame(books)\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"da_core_news_lg\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "book_df[\"lemmatized_content\"] = book_df[\"content\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f60fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique number of lemmas per book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0cc14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name translator  count_lemmas\n",
      "0     21_Eccl       1992           820\n",
      "1     26_Ezek       1992          2474\n",
      "2     12_2Kgs       1992          1982\n",
      "3      04_Num       1992          2085\n",
      "4      39_Mal       1992           419\n",
      "..        ...        ...           ...\n",
      "127  63_2John       2020           135\n",
      "128   41_Mark       2020          1509\n",
      "129   55_2Tim       2020           506\n",
      "130  62_1John       2020           344\n",
      "131   57_Phlm       2020           186\n",
      "\n",
      "[132 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "book_df = book_df.assign(count_lemmas = book_df.lemmatized_content.apply(lambda x: len(set(x.split(\" \")))))\n",
    "print(book_df[[\"name\", \"translator\", \"count_lemmas\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfcf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 1992 total number of lemmas =====\n",
      "16194\n",
      "===== 2020 total number of lemmas =====\n",
      "14329\n",
      "===\n",
      "Difference in unique lemmas between 1992 and 2020 over all the bible\n",
      "1865\n"
     ]
    }
   ],
   "source": [
    "## Calculation for Table 5\n",
    "# Unique number of lemmas across all the books\n",
    "print(\"===== 1992 total number of lemmas =====\")\n",
    "print(len(set(\" \".join(book_df[book_df.translator == \"1992\"].lemmatized_content).split(\" \"))))\n",
    "\n",
    "print(\"===== 2020 total number of lemmas =====\")\n",
    "print(len(set(\" \".join(book_df[book_df.translator == \"2020\"].lemmatized_content).split(\" \"))))\n",
    "\n",
    "print(\"===\")\n",
    "print(\"Difference in unique lemmas between 1992 and 2020 over all the bible\")\n",
    "print(len(set(\" \".join(book_df[book_df.translator == \"1992\"].lemmatized_content).split(\" \"))) - len(set(\" \".join(book_df[book_df.translator == \"2020\"].lemmatized_content).split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT1992: 13668\n",
      "NT1992: 6274\n",
      "GT2020: 12507\n",
      "NT2020: 5503\n"
     ]
    }
   ],
   "source": [
    "#word types OT1992, NT1992, OT2020, NT2020\n",
    "def all_unique_lemmas(series):\n",
    "    # Collects all lemmas across the books\n",
    "    lemma_set = set()\n",
    "    for text in series:\n",
    "        for lemma in text.split():\n",
    "            lemma_set.add(lemma.lower())\n",
    "    return len(lemma_set)\n",
    "\n",
    "groups = {\n",
    "    \"GT1992\":  book_df.query('type == \"GT\" and translator == \"1992\"')[\"lemmatized_content\"],\n",
    "    \"NT1992\":  book_df.query('type == \"NT\" and translator == \"1992\"')[\"lemmatized_content\"],\n",
    "    \"GT2020\":  book_df.query('type == \"GT\" and translator == \"2020\"')[\"lemmatized_content\"],\n",
    "    \"NT2020\":  book_df.query('type == \"NT\" and translator == \"2020\"')[\"lemmatized_content\"],\n",
    "}\n",
    "\n",
    "for k, s in groups.items():\n",
    "    print(f\"{k}: {all_unique_lemmas(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039a6a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OT1992\n",
      "NT1992\n",
      "OT2020\n",
      "NT2020\n",
      "55813\n",
      "22389\n",
      "53296\n",
      "21952\n",
      "translator  1992  2020  diff_1992_minus_2020  diff_percent_1992_vs_2020\n",
      "name                                                                   \n",
      "05_Deut     2310  1985                   325                  16.372796\n",
      "18_Job      2156  1897                   259                  13.653137\n",
      "10_2Sam     1947  1743                   204                  11.703959\n",
      "44_Acts     2260  2068                   192                   9.284333\n",
      "11_1Kgs     2090  1900                   190                  10.000000\n",
      "...          ...   ...                   ...                        ...\n",
      "32_Jonah     310   361                   -51                 -14.127424\n",
      "07_Judg     1760  1833                   -73                  -3.982542\n",
      "66_Rev      1221  1310                   -89                  -6.793893\n",
      "28_Hos       904   996                   -92                  -9.236948\n",
      "17_Esth      758   855                   -97                 -11.345029\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#calculations for Table 6 and Table 7\n",
    "\n",
    "\n",
    "\n",
    "OT1992 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"1992\")][\"count_lemmas\"].sum()\n",
    "NT1992 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"1992\")][\"count_lemmas\"].sum()\n",
    "OT2020 = book_df[(book_df[\"type\"]==\"GT\") & (book_df[\"translator\"]==\"2020\")][\"count_lemmas\"].sum()\n",
    "NT2020 = book_df[(book_df[\"type\"]==\"NT\") & (book_df[\"translator\"]==\"2020\")][\"count_lemmas\"].sum()\n",
    "\n",
    "print(\"OT1992\")\n",
    "print(\"NT1992\")\n",
    "print(\"OT2020\")\n",
    "print(\"NT2020\")\n",
    "print(OT1992)\n",
    "print(NT1992)\n",
    "print(OT2020)\n",
    "print(NT2020)\n",
    "\n",
    "token_pivot = book_df.pivot(index=\"name\", columns=\"translator\", values=\"count_lemmas\")\n",
    "token_pivot[\"diff_1992_minus_2020\"] = token_pivot[\"1992\"] - token_pivot[\"2020\"]\n",
    "token_pivot[\"diff_percent_1992_vs_2020\"] = 100 * token_pivot[\"diff_1992_minus_2020\"] / token_pivot[\"2020\"]\n",
    "token_pivot_sorted = token_pivot.sort_values(by=\"diff_1992_minus_2020\", ascending=False)\n",
    "# Rund procentkolonnen til 2 decimaler\n",
    "token_pivot[\"diff_percent_1992_vs_2020\"] = token_pivot[\"diff_percent_1992_vs_2020\"].round(2)\n",
    "print(token_pivot_sorted)\n",
    "token_pivot_sorted.to_csv(\"lemma_counts_sorted.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb012a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pivot_sorted_perc = token_pivot.sort_values(by=\"diff_percent_1992_vs_2020\", ascending=False)\n",
    "print(token_pivot_sorted_perc)\n",
    "token_pivot_sorted_perc.to_csv(\"lemma_counts_sorted_perc.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bib2020venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
